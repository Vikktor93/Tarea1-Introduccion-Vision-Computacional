{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9HI7pKHkLEa"
   },
   "source": [
    "<div>\n",
    "<img src=\"https://i.ibb.co/v3CvVz9/udd-short.png\" width=\"150\"/>\n",
    "    <br>\n",
    "    <strong>Universidad del Desarrollo</strong><br>\n",
    "    <em>Magíster en Data Science</em><br>\n",
    "    <em>Profesor: Takeshi Asahi</em><br>\n",
    "    <em>Asignatura: Visión Computacional</em><br>\n",
    "\n",
    "</div>\n",
    "\n",
    "# **Tarea 1**\n",
    "\n",
    "*Fecha de Entrega: Martes 22, Abril 2025.*\n",
    "\n",
    "**Nombre Estudiante**: Victor Saldivia Vera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrucciones\n",
    "\n",
    "1. Buscar una base de datos (dataset) de imágenes abierta. Por ejemplo, de Kaggle (https://www.kaggle.com/datasets?tags=13207-Computer+Vision). Si dispone de una base de datos propia (o tiene acceso a alguna no pública), también  puede ser utilizada. Hacer una breve descripción de esta base de datos: número de fotos, sensor con el cual fue obtenido, condiciones ambientales, tipos de elementos que aparecen (automóviles, animales, insectos, caras, entre otros)\n",
    "\n",
    "2. Buscar una aplicación interesante para ese conjunto de imágenes. Se debe justificar en un párrafo el por qué es una aplicación que valga la pena implementar o realizar. La aplicación requeriría detectar o medir algo y en forma automatizada dentro de cada imagen.\n",
    "\n",
    "3. Hacer pre-procesamiento simple:\n",
    "    + Implementar un código que realice en forma masiva un cambio de resolución de las imágenes (por ejemplo, procesar unas 100 imágenes a una resolución menor, por ejemplo, 256x256 o 512x512). Para ello, las imágenes fuente deben estar en un directorio y las de salida en uno diferente.\n",
    "    + Implementar un código que filtre (por ejemplo, gaussiano) las imágenes y las deje en un nuevo directorio.\n",
    "\n",
    "4. Indicar el plan de los siguientes pasos a seguir de acuerdo a lo que se solicita en la Tarea 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formato de la entrega:\n",
    "\n",
    "1. Debe documentar en un breve informe lo realizado: puede ser en formato pdf, o bien en un notebook. Se recomienda un notebook jupyter, de manera de poder constatar el trabajo realizado.\n",
    "\n",
    "2. Es importante apoyar los resultados lo obtenido con comentarios. En el caso de entregar un notebook se puede agregar los cometarios con celdas en formato Markdown. **No mostrar la totalidad el resultado de las imágenes procesadas**, sino más bien **mostrar solamente algunos casos que sean ilustrativos**, junto con algunos específicos que se no se ajusten al común o promedio de los resultados. Tan **importante** como mostrar estos resultados mencionados, **son los comentarios del por qué de los resultados obtenidos** o bien el por qué no pudiera ser que no se obtuvo lo esperados.\n",
    "\n",
    "3. No está permitido el uso de Herramientas de Inteligencia Artificial para generar el informe. El uso de Inteligencia Artificial Generativa solamente se remite a la sugerencia de código parcial, como copilot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rúbrica:\n",
    "\n",
    "* Presentación del Informe (30%):\n",
    "    + **Muy bueno** (5.1 -> 7.0): Estructura de trabajo y el informe clara, apreciándose orden, buena redacción y buena ortografía. \n",
    "    + **Necesita Mejoras** (3.1 -> 5.0): Estructura de secciones no muy clara, orden parcial de los contenidos, redacción necesita mejoras y/o algunas faltas ortográficas.\n",
    "    + **Deficiente** (1.0 -> 3.0): Falta estructura de secciones en el informe con los contenidos en desorden, pobre redacción y/o muchas faltas de ortografía.\n",
    "* Trabajo Realizado (40%):\n",
    "    .+ **Muy bueno** (5.1 -> 7.0): Con el dataset seleccionado (correspondiente al menos a unas cientas imágenes) se pudo procesar según lo indicado en las instrucciones, mostrando algunos 5 a 10 ejemplos seleccionados con al menos unos 3 tipos de procesamientos diferentes.\n",
    "    + **Necesita Mejoras** (3.1 -> 5.0): No se pudo procesar la totalidad de las las cientos de imágenes, sino que un par de decenas en forma manual. Solamente pudo implementar 1 a 2 tipos de procesamientos de imágenes.\n",
    "    + **Deficiente** (1.0 -> 3.0): No pudo usar un dataset, sino que menos de 10 imágenes, y pudo realizar procesamiento sobre éstas. \n",
    "* Comentarios del Informe (40%):\n",
    "    + **Muy bueno** (5.1 -> 7.0): Diferentes pasos se encuentran complementados con buenos comentarios acerca del resultados con una buena descripción de las características del dataset y su caso de uso. Los procesamientos y pasos intermedios contienen un análisis de los resultados obtenidos a través de los ejemplos seleccionados de imágenes previas y resultantes.\n",
    "    + **Necesita Mejoras** (3.1 -> 5.0): Solamente algunos pasos se encuentran comentados y no hay una buena descripción del dataset. El caso de uso o aplicación a implementar no es tan claro y hay pocos ejemplos resultantes comentados.\n",
    "    + **Deficiente** (1.0 -> 3.0): No hay claridad acerca del dataset utilizado ni el caso de uso como objetivo. No se describe ni analizan las imágenes resultantes. También se considera el caso donde no hay imágenes seleccionadas a mostrar sino que se muestra una gran cantidad de imágenes con resultados similares. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Descripción del Dataset**\n",
    "\n",
    "Descripción del dataset seleccionado:\n",
    "- **Dataset:** PlantVillage\n",
    "- **Descripción:** es un dataset de imágenes de hojas de plantas, tanto sanas como afectadas por distintas enfermedades. Fue desarrollado como parte de un proyecto de agricultura inteligente. En esta tarea ocuparé solo un subconjunto de 200 imágenes, específicamente de las clases:\n",
    "    - `Tomato_Healthy`\n",
    "    - `Tomato_Early_blight`\n",
    "- **Número Total de imágenes del Dataset:** 20.600\n",
    "- **Número de imágenes utilizadas en la tarea:** 200 (100 por clase)\n",
    "- **Condiciones ambientales**: diversas, imágenes en entornos con iluminación controlada y no controlada.\n",
    "- **Tipos de elementos**: hojas de tomate sanas y enfermas.\n",
    "- **Sensor**: Fotografías digitales tomadas por investigadores, no se especifica el modelo del sensor, pero se encuentran en en buena resolución.\n",
    "- **Tipo de imágenes:** Fotografías tomadas en ambientes naturales y domésticos.\n",
    "- **Tamaño:** Varía por imagen, entre 256x256 hasta más de 512x512 píxeles.\n",
    "- **Formato:** JPG\n",
    "\n",
    "**Fuente del Dataset**\n",
    "- Kaggle: https://www.kaggle.com/datasets/emmarex/plantdisease "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se explica el proceso previo al preprocesamiento, ya que se selecciona solo una muestra de las imagenes por un tema de computo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Selección del Subconjunto de Imágenes**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir del dataset completo de PlantVillage, se seleccionaron aleatoriamente **100 imágenes por clase** de las siguientes categorías:\n",
    "- `Tomato_Early_blight`\n",
    "- `Tomato_healthy`\n",
    "\n",
    "Estas imágenes fueron extraídas de los tres carpetas disponibles (`train`, `test`, `validation`) y copiadas a una estructura nueva para su procesamiento posterior:\n",
    "\n",
    "Este subconjunto balanceado va a permitir trabajar de forma eficiente y en las etapas posteriores del pipeline del análisis de imágenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Importación de Librerías**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from shutil import copy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta corregida según la estructura del notebook\n",
    "base_path = Path(\"./dataset\")\n",
    "splits = [\"train\", \"test\", \"validation\"]\n",
    "clases = [\"Tomato_Early_blight\", \"Tomato_healthy\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Ciclo para Contar Imagenes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Carpeta: train\n",
      "  - Tomato_Early_blight: 1600 imágenes\n",
      "  - Tomato_healthy: 2544 imágenes\n",
      "\n",
      "Carpeta: test\n",
      "  - Tomato_Early_blight: 200 imágenes\n",
      "  - Tomato_healthy: 318 imágenes\n",
      "\n",
      "Carpeta: validation\n",
      "  - Tomato_Early_blight: 200 imágenes\n",
      "  - Tomato_healthy: 320 imágenes\n"
     ]
    }
   ],
   "source": [
    "for split in splits:\n",
    "    print(f\"\\nCarpeta: {split}\")\n",
    "    for clase in clases:\n",
    "        carpeta = base_path / split / clase\n",
    "        if carpeta.exists():\n",
    "            total = len(list(carpeta.glob(\"*.jpg\"))) + \\\n",
    "                    len(list(carpeta.glob(\"*.JPG\"))) + \\\n",
    "                    len(list(carpeta.glob(\"*.jpeg\"))) + \\\n",
    "                    len(list(carpeta.glob(\"*.JPEG\")))\n",
    "            print(f\"  - {clase}: {total} imágenes\")\n",
    "        else:\n",
    "            print(f\"  - {clase}: carpeta no encontrada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta de salida\n",
    "output_path = Path(\"output\")\n",
    "output_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crean los nombres de las carpeta de destino\n",
    "nombres = {\n",
    "    \"Tomato_Early_blight\": \"Tomato-Early-blight\",\n",
    "    \"Tomato_healthy\": \"Tomato-Healthy\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crean las carpetas de destino\n",
    "for clase_destino in nombres.values():\n",
    "    (output_path / clase_destino).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ya existen 184 imágenes en 'Tomato-Early-blight'. Se omite selección y copia de imágenes\n",
      "Ya existen 195 imágenes en 'Tomato-Healthy'. Se omite selección y copia de imágenes\n"
     ]
    }
   ],
   "source": [
    "# Se recolecta y selecciona de forma aleatoria las imagenes\n",
    "for clase_origen in clases:\n",
    "    clase_destino = nombres[clase_origen]\n",
    "    carpeta_destino = output_path / clase_destino\n",
    "\n",
    "    # Verificar si ya existen 100 o más imágenes\n",
    "    existentes = list(carpeta_destino.glob(\"*.jpg\"))\n",
    "    if len(existentes) >= 100:\n",
    "        print(f\"Ya existen {len(existentes)} imágenes en '{clase_destino}'. Se omite selección y copia de imágenes\")\n",
    "        continue\n",
    "\n",
    "    # Recolección de imágenes desde todos las carpetas\n",
    "    total_imagenes = []\n",
    "    for split in splits:\n",
    "        carpeta = base_path / split / clase_origen\n",
    "        if carpeta.exists(): # lista de diversos formato de imagen\n",
    "            imagenes = list(carpeta.glob(\"*.jpg\")) + \\\n",
    "                       list(carpeta.glob(\"*.JPG\")) + \\\n",
    "                       list(carpeta.glob(\"*.jpeg\")) + \\\n",
    "                       list(carpeta.glob(\"*.JPEG\"))\n",
    "            total_imagenes.extend(imagenes)\n",
    "\n",
    "    print(f\"\\n Total de imágenes encontradas en la carpeta '{clase_origen}': {len(total_imagenes)}\")\n",
    "\n",
    "    if len(total_imagenes) < 100:\n",
    "        raise ValueError(f\"No hay suficientes imágenes en la carpeta '{clase_origen}' (se necesitan al menos 100)\")\n",
    "\n",
    "    # Selección aleatoria y copia\n",
    "    seleccionadas = random.sample(total_imagenes, 100)\n",
    "\n",
    "    for img in seleccionadas:\n",
    "        destino = carpeta_destino / img.name\n",
    "        copy2(img, destino)\n",
    "\n",
    "    print(f\"{len(seleccionadas)} imágenes copiadas a '{clase_destino}'\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Aplicación propuesta**\n",
    "La idea es hacer una especie de sistema automatizado de **clasificación de enfermedades en hojas de tomate**. Esto puede permitir identificar de manera temprana posibles infecciones como el **Early Blight**, que es una enfermedad fúngica que puede propagarse rápidamente y causar pérdidas significativas en cultivos de tomates. Mediante esta aplicación, sería posible automatizar esta tarea, reduciendo la dependencia de expertos humanos y permitiendo alertas tempranas. Además, mediante el análisis de color y textura de las hojas se puede detectar diversas enfermedades de caracter fúngicas.\n",
    "\n",
    "Si bien, en esta tarea solo se utiliza solamente las hojas de tomate, este dataset completo cuenta con fotografías de hojas de manzanas y papas.\n",
    "\n",
    "Esta tarea toma la línea de trabajo del área de la agricultura inteligente, la sustentabilidad de cultivos y el manejo eficiente de recursos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Preprocesamiento de Imágenes**\n",
    "A continuación se realizan dos tipos de preprocesamiento sobre el subconjunto de imágenes seleccionadas:\n",
    "- Redimensionamiento a resolución estándar (256x256 px)\n",
    "- Aplicación de filtro Gaussiano para suavizado\n",
    "\n",
    "Cada tipo de preprocesamiento se guarda en un nuevo directorio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Directorios de salida para imágenes preprocesadas**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "origen = Path(\"output\")\n",
    "dest_resize = Path(\"output/resized\")\n",
    "dest_blur = Path(\"output/filtered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Preprocesamiento de Imágenes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se recorre las clases de Tomato_Healthy y Tomato_Early_blight\n",
    "for clase in origen.iterdir():\n",
    "    if clase.is_dir():\n",
    "        # Se crean carpetas destino para cada clase\n",
    "        (dest_resize / clase.name).mkdir(parents=True, exist_ok=True)\n",
    "        (dest_blur / clase.name).mkdir(parents=True, exist_ok=True)\n",
    "        # Se procesan todas las imágenes .jpg de la clase\n",
    "        for img_path in clase.glob(\"*.jpg\"):\n",
    "            # Lectura de la imagen\n",
    "            img = cv2.imread(str(img_path))\n",
    "\n",
    "            # Se redimensiona las imágenes a 256x256 píxeles\n",
    "            resized = cv2.resize(img, (256, 256))\n",
    "\n",
    "            # Se aplica filtro Gaussiano (suavizado)\n",
    "            blurred = cv2.GaussianBlur(resized, (5, 5), 0)\n",
    "\n",
    "            # Guardar versiones procesadas en carpetas correspondientes\n",
    "            cv2.imwrite(str(dest_resize / clase.name / img_path.name), resized)\n",
    "            cv2.imwrite(str(dest_blur / clase.name / img_path.name), blurred)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "computer-vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
